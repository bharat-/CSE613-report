\section{Design}
\label{Design}

%Opening text...  Typical length: 3-5 pages.
%
%Hardest section to write.  A lot of possible interdependencies.
%
%If you find that you have to have a ``forward'' reference to a
%section of text you've not described yet, it usually means that the
%structure of your paper is wrong.  So avoid fwd refs.  Backward
%references to previous sections is ok, as long as it's not too far in
%the beginning of the paper.
%
%Do an outline of design even print a Table of Contents
%
%Opening: tell reader what to expect.
%
%Open with key design goals, in descending importance.
%
%General rule: whenever you LIST 2 or more items, THINK about their
%order (should it be importance order? chronological?  categorical?)
%
%(A) What are your design goals, and what do they get you?  Separate
%goals with HOW you achieve them.  Possible goals can include:
%
%- improved performance
%
%- improved scalability (same as perf.  but need to test "multiple"
%machines)
%
%- better energy consumption
%
%- improved security (hard to prove "better" security)
%
%- versatility: has more functionality that can be utilized in more
%settings.  A generalization of past specific work.
%
%- compatibility: works with many existing systems, possibly
%unmodified (or with few modifications).
%
%- other design goals?
%
%(B) briefly describe HOW you would accomplish each of your design
%goals.
%
%(C) Show a high-level architectural figure whole system, and describe
%every "box" of section of the figure.
%
%Start with high-level detail of each components, then go into greater
%detail.
%
%(D) Bulk of design: go over every design goal and architectural
%component, and describe it in detail.
%
%Key: don't just say WHAT you did, but WHY you did that.  WHY, WHY,
%WHY!
%
%Tense: past tense for what was designed, present tense to describe
%system operation.  Switch b/t past and present consistently.  NO
%future tense!
%
%-----------------------------------------------------------------------------

\paragraph{Experimental Setup}
We have used an Intel machine with SandyBridge EP processor running
Ubuntu 14.04.2 LTS with Linux kernel 3.13.0-49-generic.  CPU and
memory details are as follows:

\begin{table}[th]
\begin{center} %\caption {CPU and Memory details}\\
    \begin{tabular}{| l | l |}
    \hline
    Architecture & Intel x86\_64\\ \hline
    CPU(s) & 32\\ \hline
    Thread(s) per core & 2\\ \hline
	Core(s) per socket & 8\\ \hline
	Socket(s) & 2\\ \hline
	NUMA node(s) & 2\\ \hline
	Stepping & 7\\ \hline
	CPU MHz & 1200\\ \hline
	L1d cache & 32K\\ \hline
	L1i cache & 32K\\ \hline
	L2 cache & 256K\\ \hline
	L3 cache & 20MB\\ \hline
	NUMA node0 CPU(s) & 0-7,16-23\\ \hline
	NUMA node1 CPU(s) & 8-15,24-31\\ \hline
	MemTotal & 32GB\\ \hline
    \end{tabular}
\end{center}
\caption{\capfont CPU and Memory details}
\label{tab:Table1}
\end{table}

\paragraph{Dataset}
Datasets used in the experiment were collected from Florida Sparse
Matrix collection in Matrix Market format.  To ensure a consistent
benchmarking environment, all datasets were verified for directed
graph having a single strongly connected component.  We also have
tried to include some data sets used in the papers being benchmarked.
Our datasets vary in size and type to exhaustively cover a wide range
of real world input.

\begin{table}[th]
\begin{center} %\caption {Dataset details}\\
    \begin{tabular}{| l | l | l | l |}
    \hline
	Dataset & Type & N & M\\ \hline
    \hline
    	gre\_1107 & Small & 1107 & 4557\\ \hline
	Cell1 & Small & 7055 & 27800\\ \hline
	Appu & Small & 14000 & 1.839M\\ \hline

	Conf6\_0-8x8-80 & Medium & 49152 & 1.917M\\ \hline
	Com-dblp  & Medium & 317080 & 2.1M\\ \hline
	Com-amazon & Medium & 334863 & 1.851M\\ \hline
	Fem\_hifreq\_circuit & Medium & 491100 & 19.748M\\ \hline
	Chevron4 & Medium & 711450 & 5664962\\ \hline

	Cage14 & Large & 1.506M & 25.625M\\ \hline
	Cage15 & Large & 5.155M & 94.044M\\ \hline
	Delaunay-n24 & Large & 16.777M & 100.663M\\ \hline
    \end{tabular}
\end{center}
\caption{\capfont Graph Dataset details}
\label{tab:Table2}
\end{table}

\paragraph{Preprocessing}
We wrote converters for each of the algorithms and converted the
datasets form Matrix Market format to accepted format for the
algorithms.  To ensure the correctness of each algorithm we verified
that all vertices are being explored.

\paragraph{Algorithms used in Benchmarking}
After our detailed literature survey we shortlisted \emph{six} BFS
implementations.  Idea was to accomodate some latest work along with some
highly efficient BFS algorithms and see if they are energy efficient.
\begin{itemize}[leftmargin=*]
\item \textbf{Algorithm1}
\emph{Avoiding locks and atomic instructions in shared-memory parallel
BFS using optimistic parallelization} ~\cite{WSLDQ-BFS}.  We have used
WSLDQ (work stealing, lock free, scale free) implementation suggested
in the paper.  This algorithm uses work stealing in a lock free
setting to load balance when a thread runs out of jobs.
\item \textbf{Algorithm2}
\emph{Efficient Parallel Graph Exploration on Multi-Core CPU and GPU}
~\cite{STANFORD-BFS}. This algorithm uses a hybrid approach and
switches between various implementations based on the vertices
threshold.
\item \textbf{Algorithm3}
\emph{A Work-Efficient Parallel Breadth-First Search Algorithm}
~\cite{MIT-BFS}.  This uses bag semantics to process the nodes
belonging to a BFS layers in a parallel way.
\item \textbf{Algorithm4}
\emph{Direction-Optimizing Breadth-First Search} ~\cite{LIGRA-BFS}.
The algorithm starts with a normal top-down BFS approach, but switches to
bottom-up BFS approach when diameter of graph is maximum.  In this way
it skipps a lot of unnecessary edges, hence reducing the work.
We have used a shared memory implemented, integrated into ligra tool.
\item \textbf{Algorithm5}
Theoretically Optimized BFS, \emph{S3BFS} by (Jesmin J. Tithi, SBU).
\item \textbf{Algorithm6}
Theoretically Optimized BFS, \emph{BFS\_MIC2} by (Jesmin J. Tithi, SBU).
\end{itemize}

\paragraph{Tools used in Benchmarking}
We used easy to use command line tools provided as a part of likwid
project. For our benchmarking purposes we used the following:
\begin{itemize}[leftmargin=*]
\item \textbf{LikwidPerfCtr}
It is a simple lightweight command line tool to measure hardware
performance counters end to end. The Linux msr module provides an
interface to access model specific registers from user space.  The
tool uses the same to read out hardware performance counters with an
unmodified linux kernel. We used the following command:\newline
\emph{likwid-perfctr -c $<$cores$>$ -g $<$event$>$ -M $<$type-of-access$>$ -O}
\item \textbf{LikwidPowermeter}
Intel recently introduced an interface to configure and readout energy
consumption of processors and memory. This so called RAPL interface is
controlled through MSR registers. likwid-powermeter is a small tool
which allows you to query the energy consumed within a package for a
given time period and computes the resulting power consumption. For
LikwidPowermeter reading we used following command:\newline
\emph{likwid-powermeter -c $<$socket$>$ -M $<$type-of-access$>$}\newline
%iiWe took reading for both socket 0 and socket 1.
\item \textbf{numactl}
Other than the likwid tools we used \emph{numactl}, a utility which
can be used to control NUMA policy for processes or shared memory.
\emph{numactl $<$option$>$ $<$nodes$>$}
\end{itemize}

\begin{table}[th]
\begin{center}
    \begin{tabular}{| l | l | l | l | l | l | l |}
    \hline
	Dataset &  Algo6 (-i) & Algo6 (-m)\\ \hline
    \hline
	Gre & 1.33 &  \cellcolor{green!25}1.27\\ \hline
	Cell1 & 4.73 & \cellcolor{green!25}4.64\\ \hline
	Appu & 175.06 & \cellcolor{green!25}170.83\\ \hline
	Conf6 & \cellcolor{green!25}185.85 & 192.96 \\ \hline
	Dblp & \cellcolor{green!25}235.14 & 237.94\\ \hline
	Amazon & \cellcolor{green!25}208.34 & 222.69\\ \hline
	Fem & \cellcolor{green!25}2102.01 & 2115.32\\ \hline
	Chevron & \cellcolor{green!25}640.16 & 646.02\\ \hline
	Cage14 & 2973.07 & \cellcolor{green!25}2935.45\\ \hline
	Cage15 & 11452.49 & \cellcolor{green!25}11328.38\\ \hline
	Delaunay & \cellcolor{green!25}12677.84 & 12878.08\\ \hline
    \end{tabular}
\end{center}
\caption{\capfont Effect of numactl -i vs -m on ENERGY in Algorithm6,
Energy (in Joules)}
\label{tab:Table7}
\end{table}


\paragraph{Experimental readings}
In likwid-perfctr readings, out of the various pre-configured event
sets, we used the following:
\begin{itemize}[leftmargin=*]
\item MEM: The event gives Main Memory's Read, Write \& Total 
Bandwidth in MBytes/sec. It also gives the Datavolume in GBytes.
\item L2CACHE: The event gives L2 cache miss rate/ratio.
\item L3CACHE: The event primarily gives L3 cache miss rate/ratio.
\end{itemize}
For likwid-perfctr we took the readings on core 0 to 15, and for
likwid-powermeter, we took readings of socket 0 \& 1.\newline 
%We took the aggregated reading on all available cores of both Socket 0 \& 1.
We compared numactl with -i and -m option, and observed that in
general both of them had same performance in terms of energy as shown
in Table\ref{tab:Table7}, but -i gives better cache performance, hence
we used -i in our experiment.  We have used CILKNWORKERS=16 in our
experiments fixing the total thread count to 16.

To remove anamolies from experimental readings, we ran the experiment
7 times, removed the best and worst readings and then reported the
average of the remaining 5 readings.

%\subsection{System Operation}
%
%Example of subsection...
%
%%-----------------------------------------------------------------------------
%\paragraph{Garbage collection}
%%
%Example of a pragraph heading.
%
%\begin{figure}[htbp] \begin{centering}
%\epsfig{file=figures/lba-ind-example.eps,angle=270,width=1.00\linewidth}
%\caption{LBA indirection example.  The host first writes LBAs 23,
%352, 53, 63, 64, 65, 52, and 29.  The second write sequence is 75,
%76, 23, 52, 324, 263, and 636.  This causes LBAs 23 and 52 to become
%garbage.  Moreover, reading LBAs sequentially requires reading ABAs
%randomly.} \label{fig:lba-ind} \end{centering} \end{figure}
%
%
%Here's how you refer to Figure~\ref{fig:lba-ind}.
%
%\begin{itemize}
%
%\item itemized list item 1
%
%\item item 2
%
%\end{itemize}
%
%
%\textbf{* TENSE USE: past, present, and future}
%
%By default, everything should be written in PAST tense.  "We designed
%a system and evaluated it."
%
%Use present tense ONLY to describe system operation.  "Our system
%sends a message to the server."
%
%Use future tense ONLY in "future work" section!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% For Emacs:
% Local variables:
% fill-column: 70
% End:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% For Vim:
% vim:textwidth=70
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LocalWords:
